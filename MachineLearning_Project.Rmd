---
title: "Practical Machine Learning - Final Project - Prediction"
author: "Karthik Radhakrishnan"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---
#### 12 May, 2017

## Executive Summary
The objective of the project is to predict the manner in which 6 participants performed weight lifting exercises. The data is collected from accelerometers on the belt, forearm, arm, and dumbell of the  participants. The outcome variable has five classes and the total number of predictors are 159.

## About the Data Set
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Objective of the Assignment
Predicting the manner in which the participants did the exercise. Refer to the "classe" variable in the training set. All other variables can be used as predictor.

Show how the model was built, performed cross validation, and expectation of the sample error and reasons of choices made.

Use the prediction model to predict 20 different test cases.

## Processing
### Load necessary libraries
```{r}
library(caret)
library(rpart)
library(knitr)
library(randomForest)
library(ElemStatLearn)
library(corrplot)
set.seed(888) # For research reproducibility purpose
```

### Download and Read Data 
Download the file if required and read
```{r}
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile)
}

trainRaw <- read.csv("./data/pml-training.csv",header=T,sep=",",na.strings=c("NA",""))
testRaw <- read.csv("./data/pml-testing.csv",header=T,sep=",",na.strings=c("NA",""))
dim(trainRaw)
```
```{r}
dim(testRaw)
```
The training data set contains 19622 observations and 159 predictors, while the testing data set contains 20 observations and predictors variables. The "classe" variable in the training set is the outcome to predict.
## Partitioning the Data as required
Now we split the preprocessed training data into training set and validation set.
```{r}
trainRaw <- trainRaw[,-1] # Remove the first column that represents a ID Row
inTrain = createDataPartition(trainRaw$classe, p=0.60, list=F)
training = trainRaw[inTrain,]
validating = trainRaw[-inTrain,]
```
## Data Cleansing
For a RandomForest model the data set must be checked on possibility of columns with no data. The decision is made whereby all the columns that having less than 60% of data filled are removed.    
```{r}
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training))) # Number of columns with less than 60% of data
```    

```{r}
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training))) # Number of columns with less than 60% of data
```    

Next, the criteria to remove columns that do not satisfy the requirement is applied before applying to the model.

```{r}
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]
```

## Modeling
In random forests, cross-validation or a separate test set to get an unbiased estimate of the test set error is not required as it is estimated internally, during the execution. Therefore, we can proceed with the training of the model (Random Forest) using the training data set.

```{r}
model <- randomForest(classe~.,data=training)
model
```    
## Evaluate the Model
Evaluate the importance variable from the model generated by random Forest
```{r}
importance(model)
```    
Let us evaluate the model now through the confusion Matrix.
```{r}
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)
```    

The accuracy for the validating data set is calculated with the following formula:
```{r}
acrcy<-c(as.numeric(predict(model,newdata=validating[,-ncol(validating)])==validating$classe))
acrcy<-sum(acrcy)*100/nrow(validating)
```
Model Accuracy as tested over Validation set = 99.8725465% The out-of-sample error is 0.13%, which is pretty low.

## Model Testing
For the model testing, the new values are predicted using the testing dataset which was loaded earlier. Data cleansing was first performed and all columns of Testing data set are coerced for the same class of previous data set.

```{r}
testRaw <- testRaw[,-1] # Remove the first column that represents a ID Row
testRaw <- testRaw[ , Keep] # Keep the same columns of testing dataset
testRaw <- testRaw[,-ncol(testRaw)] # Remove the problem ID
```

### Transformation and Coercion
```{r}
# Coerce testing dataset to same class and structure of training dataset 
testing <- rbind(training[100, -59] , testRaw) 

# Apply the ID Row to row.names and 100 for dummy row from testing dataset 
row.names(testing) <- c(100, 1:20)
```

## Prediction with Test Data
```{r}
predictions <- predict(model,newdata=testing[-1,])
predictions
```

## Generation of Answers for Assignment Submission
The function pml_write_files is to create the answers files for the Prediction Assignment Submission:
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./answers/problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```
